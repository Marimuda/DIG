{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PGExplainer on BA-Shapes dataset for 2-layer GCN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dig.xgraph.dataset import SynGraphDataset\n",
    "from dig.xgraph.models import *\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url, extract_zip\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def index_to_mask(index, size):\n",
    "    mask = torch.zeros(size, dtype=torch.bool, device=index.device)\n",
    "    mask[index] = 1\n",
    "    return mask\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    indices = []\n",
    "    num_classes = 4\n",
    "    train_percent = 0.7\n",
    "    for i in range(num_classes):\n",
    "        index = (dataset.data.y == i).nonzero().view(-1)\n",
    "        index = index[torch.randperm(index.size(0))]\n",
    "        indices.append(index)\n",
    "\n",
    "    train_index = torch.cat([i[:int(len(i) * train_percent)] for i in indices], dim=0)\n",
    "\n",
    "    rest_index = torch.cat([i[int(len(i) * train_percent):] for i in indices], dim=0)\n",
    "    rest_index = rest_index[torch.randperm(rest_index.size(0))]\n",
    "\n",
    "    dataset.data.train_mask = index_to_mask(train_index, size=dataset.data.num_nodes)\n",
    "    dataset.data.val_mask = index_to_mask(rest_index[:len(rest_index) // 2], size=dataset.data.num_nodes)\n",
    "    dataset.data.test_mask = index_to_mask(rest_index[len(rest_index) // 2:], size=dataset.data.num_nodes)\n",
    "\n",
    "    dataset.data, dataset.slices = dataset.collate([dataset.data])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = SynGraphDataset('./datasets', 'BA_shapes')\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.x = dataset.data.x[:, :1]\n",
    "# dataset.data.y = dataset.data.y[:, 2]\n",
    "dim_node = dataset.num_node_features\n",
    "dim_edge = dataset.num_edge_features\n",
    "# num_targets = dataset.num_classes\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "splitted_dataset = split_dataset(dataset)\n",
    "splitted_dataset.data.mask = splitted_dataset.data.test_mask\n",
    "splitted_dataset.slices['mask'] = splitted_dataset.slices['train_mask']\n",
    "dataloader = DataLoader(splitted_dataset, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load model and checkpoints"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_checkpoints(root='./'):\n",
    "    if osp.exists(osp.join(root, 'checkpoints')):\n",
    "        return\n",
    "    url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "    path = download_url(url, root)\n",
    "    extract_zip(path, root)\n",
    "    os.unlink(path)\n",
    "\n",
    "model = GCN_2l(model_level='node', dim_node=dim_node, dim_hidden=300, num_classes=num_classes)\n",
    "model.to(device)\n",
    "check_checkpoints()\n",
    "ckpt_path = osp.join('checkpoints', 'ba_shapes', 'GCN_2l', '0', 'GCN_2l_best.ckpt')\n",
    "model.load_state_dict(torch.load(ckpt_path)['state_dict'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dig.xgraph.method import PGExplainer\n",
    "explainer = PGExplainer(model, in_channels=600, device=device, explain_graph=False)\n",
    "\n",
    "explainer.train_explanation_network(splitted_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup for evaluation and get the explanation results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# --- Create data collector and explanation processor ---\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "x_collector = XCollector()\n",
    "\n",
    "### Run explainer on the given model and dataset\n",
    "index = -1\n",
    "for i, data in enumerate(dataloader):\n",
    "    for j, node_idx in enumerate(torch.where(data.test_mask)[0].tolist()):\n",
    "        index += 1\n",
    "        print(f'explain graph {i} node {node_idx}')\n",
    "        data.to(device)\n",
    "\n",
    "        if torch.isnan(data.y[0].squeeze()):\n",
    "            continue\n",
    "\n",
    "        walks, masks, related_preds = \\\n",
    "            explainer(data.x, data.edge_index, node_idx=node_idx, y=data.y, top_k=10)\n",
    "\n",
    "        x_collector.collect_data(masks, related_preds)\n",
    "\n",
    "        # if you only have the edge masks without related_pred, please feed sparsity controlled mask to\n",
    "        # obtain the result: x_processor(data, masks, x_collector)\n",
    "        if index >= 99:\n",
    "            break\n",
    "\n",
    "    if index >= 99:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The final result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Fidelity: {x_collector.fidelity:.4f}\\n'\n",
    "      f'Sparsity: {x_collector.sparsity:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}